{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T21:24:53.411304Z",
     "start_time": "2024-10-08T21:24:52.091568Z"
    }
   },
   "source": [
    "from pymab.policies.ucb import StationaryUCBPolicy\n",
    "from pymab.policies.bayesian_ucb import BayesianUCBPolicy\n",
    "from pymab.game import Game"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pymc3:The version of PyMC you are using is very outdated.\n",
      "\n",
      "Please upgrade to the latest version of PyMC https://www.pymc.io/projects/docs/en/stable/installation.html\n",
      "\n",
      "Also notice that PyMC3 has been renamed to PyMC.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T21:24:53.581225Z",
     "start_time": "2024-10-08T21:24:53.412468Z"
    }
   },
   "source": [
    "# Define Q-values, which are the true values of the bandits\n",
    "# For bernoulli distribution, the values should always be between 0 and 1.\n",
    "Q_values = [0.1, 0.8, 0.3, 0.4, 0.9, 0.2, 0.25, 0.6, 0.5, 0.35]\n",
    "n_bandits = 10\n",
    "\n",
    "reward_distribution = 'bernoulli'\n",
    "\n",
    "ucb_policy_0 = StationaryUCBPolicy(n_bandits=n_bandits,\n",
    "                      c=0, reward_distribution=reward_distribution)\n",
    "\n",
    "ucb_policy_1 = StationaryUCBPolicy(n_bandits=n_bandits,\n",
    "                      c=1, reward_distribution=reward_distribution)\n",
    "\n",
    "ucb_policy_2 = StationaryUCBPolicy(n_bandits=n_bandits,\n",
    "                      c=2, reward_distribution=reward_distribution)\n",
    "\n",
    "bayesian_ucb = BayesianUCBPolicy(n_bandits=n_bandits, reward_distribution=reward_distribution)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class UCBPolicy with abstract method _calculate_confidence_interval",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m n_bandits \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m      5\u001B[0m reward_distribution \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbernoulli\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 7\u001B[0m ucb_policy_0 \u001B[38;5;241m=\u001B[39m \u001B[43mUCBPolicy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_bandits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_bandits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreward_distribution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreward_distribution\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m ucb_policy_1 \u001B[38;5;241m=\u001B[39m UCBPolicy(n_bandits\u001B[38;5;241m=\u001B[39mn_bandits,\n\u001B[1;32m     11\u001B[0m                       c\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, reward_distribution\u001B[38;5;241m=\u001B[39mreward_distribution)\n\u001B[1;32m     13\u001B[0m ucb_policy_2 \u001B[38;5;241m=\u001B[39m UCBPolicy(n_bandits\u001B[38;5;241m=\u001B[39mn_bandits,\n\u001B[1;32m     14\u001B[0m                       c\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, reward_distribution\u001B[38;5;241m=\u001B[39mreward_distribution)\n",
      "\u001B[0;31mTypeError\u001B[0m: Can't instantiate abstract class UCBPolicy with abstract method _calculate_confidence_interval"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T21:25:04.428972Z",
     "start_time": "2024-10-08T21:25:04.408852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup the game\n",
    "game = Game(n_episodes=2000, \n",
    "            n_steps=1000, \n",
    "            Q_values=Q_values,\n",
    "            policies=[ucb_policy_0,\n",
    "                    ucb_policy_1,\n",
    "                    ucb_policy_2,\n",
    "                    bayesian_ucb\n",
    "                ], \n",
    "            n_bandits=n_bandits,\n",
    "            )"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ucb_policy_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Setup the game\u001B[39;00m\n\u001B[1;32m      2\u001B[0m game \u001B[38;5;241m=\u001B[39m Game(n_episodes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2000\u001B[39m, \n\u001B[1;32m      3\u001B[0m             n_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, \n\u001B[1;32m      4\u001B[0m             Q_values\u001B[38;5;241m=\u001B[39mQ_values,\n\u001B[0;32m----> 5\u001B[0m             policies\u001B[38;5;241m=\u001B[39m[\u001B[43mucb_policy_0\u001B[49m,\n\u001B[1;32m      6\u001B[0m                     ucb_policy_1,\n\u001B[1;32m      7\u001B[0m                     ucb_policy_2,\n\u001B[1;32m      8\u001B[0m                     bayesian_ucb\n\u001B[1;32m      9\u001B[0m                 ], \n\u001B[1;32m     10\u001B[0m             n_bandits\u001B[38;5;241m=\u001B[39mn_bandits,\n\u001B[1;32m     11\u001B[0m             )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ucb_policy_0' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T21:25:08.647715Z",
     "start_time": "2024-10-08T21:25:08.627647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the game\n",
    "game.game_loop()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'game' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Run the game\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mgame\u001B[49m\u001B[38;5;241m.\u001B[39mgame_loop()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'game' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for policy in game.policies:\n",
    "    policy.plot_distribution()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot the results\n",
    "game.plot_average_reward_by_step()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "game.plot_average_reward_by_step_smoothed()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "game.plot_rate_optimal_actions_by_step()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
