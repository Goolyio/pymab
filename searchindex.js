Search.setIndex({"alltitles": {"Bayesian UCB (bayesian_ucb.py)": [[2, "bayesian-ucb-bayesian-ucb-py"]], "Contents:": [[1, null]], "Contextual Bandits (contextual_bandits.py)": [[2, "contextual-bandits-contextual-bandits-py"]], "Epsilon Greedy (epsilon_greedy.py)": [[2, "epsilon-greedy-epsilon-greedy-py"]], "Example Usage": [[0, "example-usage"], [2, "example-usage"], [3, "example-usage"]], "Game (game.py)": [[0, "game-game-py"]], "Game documentation": [[0, null]], "Gradient (grandient.py)": [[2, "gradient-grandient-py"]], "Greedy (greedy.py)": [[2, "greedy-greedy-py"]], "Indices and tables": [[1, "indices-and-tables"]], "Policies documentation": [[2, null]], "Policy (policy.py)": [[2, "policy-policy-py"]], "PyMAB documentation": [[1, null]], "Reward Distribution (reward_distribution.py)": [[3, "reward-distribution-reward-distribution-py"]], "Reward Distribution documentation": [[3, null]], "Simple Example": [[1, "simple-example"]], "Softmax Selection (greedy.py)": [[2, "softmax-selection-greedy-py"]], "Thompson Sampling (greedy.py)": [[2, "thompson-sampling-greedy-py"]], "UCB (ucb.py)": [[2, "ucb-ucb-py"]]}, "docnames": ["game", "index", "policies", "reward_distribution"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["game.rst", "index.rst", "policies.rst", "reward_distribution.rst"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"1": 1, "1000": 1, "2000": 1, "5": 1, "The": 1, "add": [0, 2, 3], "algorithm": 1, "allow": 1, "an": 1, "arm": 1, "bandit": 1, "bayesian": 1, "bayesian_ucb": 1, "compar": 1, "configur": 1, "contextu": 1, "contextual_bandit": 1, "defin": 1, "design": 1, "differ": 1, "distribut": 1, "easi": 1, "epsilon": 1, "epsilon_greedi": 1, "experi": 1, "exploit": 1, "explor": 1, "exploratori": 1, "flexibl": 1, "framework": 1, "from": 1, "game": 1, "game_loop": 1, "gradient": 1, "grandient": 1, "greedi": 1, "greedy_polici": 1, "greedypolici": 1, "i": 1, "import": 1, "index": 1, "lever": 1, "librari": 1, "modul": 1, "multi": 1, "multipl": 1, "n_bandit": 1, "n_episod": 1, "n_step": 1, "offer": 1, "optimistic_initi": 1, "page": 1, "perform": 1, "plot": 1, "plot_average_reward_by_step": 1, "polici": 1, "pull": 1, "py": 1, "python": 1, "quickli": 1, "random": 1, "result": 1, "reward": 1, "reward_distribut": 1, "right": 1, "run": 1, "sampl": 1, "scenario": 1, "search": 1, "select": 1, "set": 1, "sidekick": 1, "softmax": 1, "tame": 1, "thompson": 1, "thompson_sampl": 1, "thompsonsamplingpolici": 1, "todo": [0, 2, 3], "trusti": 1, "ts_polici": 1, "ucb": 1, "up": 1, "us": 1, "usag": 1, "user": 1, "varieti": 1, "wild": 1, "world": 1, "your": 1}, "titles": ["Game documentation", "PyMAB documentation", "Policies documentation", "Reward Distribution documentation"], "titleterms": {"bandit": 2, "bayesian": 2, "bayesian_ucb": 2, "content": 1, "contextu": 2, "contextual_bandit": 2, "distribut": 3, "document": [0, 1, 2, 3], "epsilon": 2, "epsilon_greedi": 2, "exampl": [0, 1, 2, 3], "game": 0, "gradient": 2, "grandient": 2, "greedi": 2, "indic": 1, "polici": 2, "py": [0, 2, 3], "pymab": 1, "reward": 3, "reward_distribut": 3, "sampl": 2, "select": 2, "simpl": 1, "softmax": 2, "tabl": 1, "thompson": 2, "ucb": 2, "usag": [0, 2, 3]}})